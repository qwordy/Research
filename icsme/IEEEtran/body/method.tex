\section{Methodology}
\label{sec:method}
This section presents our research questions (Section~\ref{sec:method:rq}), our data set (Section~\ref{sec:method:data}), and our support tool (Section~\ref{sec:method:tool}).
\subsection{Research questions}
\label{sec:method:rq}
To understand how concurrency code is maintained, in this study, we focus on the following research questions:

\textbf{RQ1.} What patterns are followed when programmers maintain concurrency code?

In each day, programmers can make numerous commits. Based on their analysis on commits, Kim and Notkin~\cite{conf/icse/KimN09} find that code changes can be repetitive, and Martinez \emph{et al.}~\cite{conf/icsm/MartinezDM13} further extract change patterns to denote such repetitive changes. However, the change patterns of concurrency programming is rarely studied. The recent study~\cite{conf/sigsoft/GuJSZL15} mainly focuses on changes only on critical sections. As a result, this research question is still largely open. To explore this research question, we carefully put our selected concurrent-related commits into \zhong{??} categories (see Section~\ref{sec:result:rq1} for details).


\textbf{RQ2.} How useful are our extract change patterns, when programmers maintain concurrency code?

To assess the usefulness of our extracted change patterns, we search open source search code in open-source projects with our change patterns. In particular, \zhong{Please explain how you build queries for the search, and how to write your pull requests.} Our changes have been accepted by the owner of some project\footnote{https://github.com/derekmu/Schmince-2}. In Section~\ref{sec:result:sample}, ...



\textbf{RQ3.} What are the change trends of using parallel APIs?

J2SE provides standard APIs\footnote{\url{https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/package-summary.html}} for developing concurrency code. Alternatively, programmers can use third-party libraries such as Apache Commons\footnote{\url{https://commons.apache.org/}} and Guava\footnote{\url{https://github.com/google/guava}}, since they provide similar and extensive functions. In practice, programmers can choose different APIs to implement their concurrency code. Their different choices can lead to different change trends that can be examined through their revision histories. For example, a parallel API can be difficult to use, so programmers have to constantly modify corresponding code, during software maintenance. In Section~\ref{sec:result:trend}, we count commits that involve different parallel APIs over time. We find that ?? types of change trends. \zhong{Please add details.}

\textbf{RQ4.} How frequent are concurrency code modified?





which are both very famous libraries providing reusable components. Although developers can use their own concurrent-related classes or third-party libraries, they are always using the facilities provided by Java standard libraries in most cases except they are facing special and rigour requirement. Previous researches \cite{journals/jss/PintoTFFB15, journals/infsof/WuCZX16, conf/sigsoft/OkurD12} investigated the usage of concurrent libraries. We want to know how frequent (do) concurrent-related code change occur in software projects and what the differences of frequency in different kinds of software projects are.

We use our tool to count the number of concurrent-related code changes and visualize the statistics. We use a method of machine learning combined with textual analysis to decide whether a commit in history is concurrent-related or not.

\subsection{Data set}
\label{sec:method:data}
We investigate 7 Java open-source projects from Github including Hadoop, Tomcat, Cassandra\footnote{http://cassandra.apache.org/}, Lucene-solr\footnote{http://lucene.apache.org/}, Netty\footnote{http://netty.io/}, Flink\footnote{https://flink.apache.org/} and Mahout\footnote{http://mahout.apache.org/} as shown in Table 1. Some projects are mirrored in Github. They are all popular, large-scale, active, representative Java open-source projects and cover different areas like distributed computing, web server, database, information retrieval, I/O and machine learning. The Hadoop project develops open-source software for reliable, scalable, distributed computing and has become one of the most famous Java open-source software for many years. Tomcat is the most popular implementation of the Java Servlet, JavaServer Pages, Java Expression Language and Java WebSocket technologies. Cassandra \cite{journals/sigops/LakshmanM10} is a database system which can Manage massive amounts of data, fast, without losing sleep. Lucene-solr is two projects together in one respository in Github. Lucene is a search engine library and solr is a search engine server which uses lucene. Netty is an event-driven asynchronous network application framework. Flink is an open source stream processing framework with powerful stream- and batch-processing capabilities. Mahout is a machine learning project. Table I shows the lines of code in Java, the number of Java files, the number of commits and the number of selected concurrent-related commits, which are examined by us, of each project. All the projects are checked out for our study in December 2016.

\begin{table}
	\centering
	\caption{Projects Information (LOC and \#Files are both of Java files)}
	\begin{tabular}{|c|c|c|c|c|}\hline
		Project&LOC&\#Files&\#Commits&\#Selected Commits\\\hline
		Hadoop&1,202,764&7,701&14,930&49\\\hline
		Tomcat&301,173&2,192&17,731&159\\\hline
		Cassandra&387,980&2,143&21,982&48\\\hline
		Lucene-solr&918,398&6,310&26,152&74\\\hline
		Netty&218,131&2,054&7,759&202\\\hline
		Flink&414,264&4,068&9,771&28\\\hline
		%Guava&251,205&1,672&3,850\\\hline
		Mahout&109,584&1,215&3,703&0\\\hline
	\end{tabular}
\zhong{Add a total row. Remove Mahout, since you did not analyze its commits.}
\end{table}

\subsection{Tool support}
\label{sec:method:tool}
We have developed a tool to collect and analyze data. The tool has the following functions.

\subsubsection{Collecting commits}
All the projects of our study are under git which is one of the most popular version control systems in the world. Some projects of the study used svn or some other version control systems before because they have long histories, but they all support git \cite{books/daglib/0022839} now. We employ JGit, a lightweight, pure Java library implementation of git, to retrieve all the commit logs in projects' histories. A typical commit log contains commit id which is a 20-character-long string uniquely identifying a commit, author, date and message. Once we get a commit id, we use \texttt{git show} command to show the log message and textual \texttt{diff}. The \texttt{diff} result contains one or more change files which contain one or more change hunks.

\subsubsection{Classification}
There are many commits which are not concurrent-related in the commits which we have collected. We need to select concurrent-related commits. We can match keywords in commit messages. Tian \emph{et al.} gave a successful example of identifing bug fixing patches using machine learning \cite{conf/icse/TianLL12}. We use machine learning to train and predict whether a commit is concurrent-related. We adopt both text analysis and code analysis to extract features. A commit log uses natural language to present what was changed and why the change was made in most cases. We treat each commit log as a bag of words then match the words to a set of concurrent keywords which we have defined as the Java concurrent keywords like \texttt{synchronized}, \texttt{volatile} and names of common classes or interfaces in Java libraries which are related to concurrency. We also do a code analysis based on the \texttt{diff} result. 12 features are extracted for each commit, which is shown in Table II. The first column shows the feature names and the second column shows the explanations.

We use the SVM \cite{journals/ml/CortesV95} algorithm to train and classify commits as concurrent-related or not. SVM is a supervised classification algorithm which needs both positive and negative labeled data for training. In our tool, we use an implementation of SVM, LIBSVM \cite{libsvm}. We manually label some data as a training data set first then train a model. The trained classifier selects 135 positive instances from all the commits which we have collected.

Finally we have 561 potential concurrent-related commits selected by keyword matching of commit message and 135 commits by using machine learning.

\begin{table}
	\centering
	\caption{Features of Data}
	\begin{tabular}{|c|c|}\hline
		Feature&Explanation\\\hline
		msgKey&Number of keywords in commit message\\\hline
		file&Number of files in a commit\\\hline
		hunk&Number of hunks in a commit\\\hline
		lineAdd&Number of added lines in a commit\\\hline
		lineRemove&Number of removed lines in a commit\\\hline
		lineSub&lineAdd - lineRemove\\\hline
		lineSum&lineAdd + lineRemove\\\hline
		keyAdd&Number of added keywords in a commit\\\hline
		keyRemove&Number of removed keywords in a commit\\\hline
		keySub&keyAdd - keyRemove\\\hline
		keySum&keyAdd + keyRemove\\\hline
		contextKey&Number of keywords in context code\\\hline
	\end{tabular}
\end{table}

\subsection{Workflow}

\textbf{RQ1.} We first need to select concurrent-related commits from repositories. A concurrent-related commit here is defined as a commit which performs code changes about concurrent programming. It hard to give a concise definition. But a concurrent-related commit is usually correlated with synchronization, thread, concurrent class, etc. We use our tool to do this job. We use textual analysis and machine learning.

Once we have set prepared set of concurrent-related commits, we manually analyze these potential concurrent-related commits to understand the changes made to code. Here is an example. We list part of lines. The first several lines describe the metadata of this commit. The rest describes differences between two versions of code.

\begin{lstlisting}
commit 563e546236217dace58a8031d56d08a27e08160b
Author: zentol <s.motsu@web.de>
Date:   Mon Jan 26 11:07:53 2015 +0100
[FLINK-1419] [runtime] Fix: distributed cache properly synchronized
This closes #339

public FutureTask<Path> createTmpFile(String name, DistributedCacheEntry entry, JobID jobID) {
-    synchronized (count) {
-      Pair<JobID, String> key = new ImmutablePair<JobID, String>(jobID, name);
-      if (count.containsKey(key)) {
-        count.put(key, count.get(key) + 1);
+    synchronized (lock) {
+      if (!jobCounts.containsKey(jobID)) {
+        jobCounts.put(jobID, new HashMap<String, Integer>());
+      }
+      Map<String, Integer> count = jobCounts.get(jobID);
+      if (count.containsKey(name)) {
+        count.put(name, count.get(name) + 1);
       } else {
-        count.put(key, 1);
+        count.put(name, 1);
       }
     }
\end{lstlisting}

We will show how we examine the changes. We first read the commit message to understand what this commit does and why. If the message explicitly involves concurrency, it will enhance our confidence that this one deserves our attention. Then we scan the differences and try to find concurrency keywords. If we find occurrence of concurrency keywords, we will read the nearby code. The ``+'' symbol marks the line as added line while the ``-'' symbol marks the line as removed line. But differences are usually insufficient for us to understand the changes because some important contexts are not shown in this kind of file. So if we find something confusing, for example, we do not know the type and definition of a variable, we will consult the original and modified versions of full files for help. For example, we cannot know the type and definition of variable \texttt{count} and \texttt{lock}. With help of full files, we know the types of them are \texttt{Map} and \texttt{Object} respectively.

\textbf{RQ2.} We first decide whether a commit is concurrent-related or not through the method described before. For each project's each month, we count the total number of commits and the number concurrent-related commits. We also calculate the percentage of concurrent-related commits. We draw figures to show them visually.

\textbf{RQ3.} We take all commits of the 7 projects into consideration. We count the occurrence times of each concurrent-related class in the added lines or the deleted lines of each month during history. We use tables and figures to show them clearly.

\textbf{RQ4.} It is hard to read tremendous amount of source code of open-source projects line by line to find which piece of concurrent-related code can be applied with the patterns. We search the keywords of pattern in repositories.

%\begin{figure}
%	\centering
%	\includegraphics[width=2in]{workflow}
%	\caption{Workflow}
%\end{figure}

%Figure 1 shows the basic workflow of our study. We first collect all the commits from the 7 projects using our tool. Then we use textual analysis and machine learning to select concurrent-related commits using our tool. Finally we manually analyze the potential concurrent-related commits to understand them.

%The first two steps have been described in Section Tool Support. Now we have got potential concurrent-related commits.
