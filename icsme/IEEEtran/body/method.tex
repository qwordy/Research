\section{Methodology}
\label{sec:method}
This section presents the research questions (Section~\ref{sec:method:rq}), the data set (Section~\ref{sec:method:data}), and the support tools (Section~\ref{sec:method:tool}) of our study.
\subsection{Research questions}
\label{sec:method:rq}
To understand how concurrent code is maintained, in this study, we focus on the following research questions:

\textbf{RQ1.} What change patterns are followed when programmers maintain concurrent code?

We define change patterns in this paper as abstract description of similar code changes that appear many times in code revision history. Based on their analysis on commits, Kim and Notkin~\cite{conf/icse/KimN09} found that code changes can be repetitive, and Martinez \emph{et al.}~\cite{conf/icsm/MartinezDM13} further extracted change patterns to denote such repetitive changes. However, to the best of our knowledge, no previous study explored the change patterns of concurrent programming, and this research question is still largely open. In our empirical study, we summarize concurrency-related commits into five change patterns, and present examples to explain our change patterns (see Section~\ref{sec:result:pattern} for details).

\textbf{RQ2.} How useful are our extracted change patterns, when programmers maintain concurrent code?

To assess the usefulness of our extracted change patterns, we search matching code in open-source projects with our change patterns. We manually exterminate return code. If a change pattern applies to such code, we fork the source files. After that we make our changes, and submit our pull request. Two of our pull requests are already confirmed and accepted by their programmers (see Section~\ref{sec:result:sample} for more details).



\subsection{Dataset}
\label{sec:method:data}
In this study, we collected commits from six Apache\footnote{\url{http://www.apache.org/}} projects. Table~\ref{table:dataset} shows the details of our data set. We selected these projects, since they are all popular and active. These projects cover various types of projects such as distributed computing, web server, database, information retrieval, and network. For example, Hadoop is one of the most popular distributed computing frameworks in Java. Tomcat is a popular web server. Column ``\#Commits'' lists number of commits. Column ``\#Concurrency'' lists number of concurrency-related commits. From these concurrency-related commits, we selected a subset for manual analysis. Column ``\#Manual'' lists number of our selected commits. We checked out all the commits in December 2016. We next explain how to identify concurrency-related commits.

\begin{table}
	\centering
	\caption{Selected Commits}\vspace*{-2ex}
    \label{table:dataset}
	\begin{tabular}{|c|r|r|r|r|}\hline
		Project&\#Commits&\#Concurrency&\#Manual\\\hline
		Hadoop&14,930&2,739&64\\
		Tomcat&17,731&1,963&207\\
		Cassandra&21,982&1,904&78\\
		Lucene-solr&26,152&2,375&99\\
		Netty&7,759&1,387&210\\
		Flink&9,771&1,500&38\\\hline
		%Guava&251,205&1,672&3,850\\\hline
		%Mahout&109,584&1,215&3,703&0\\\hline
		Total&98,325&11,868&696\\\hline
	\end{tabular}\vspace*{-3ex}
\end{table}

\subsection{Study mechanism}
\label{sec:method:tool}
As introduced in Section~\ref{sec:intro}, it is quite difficult to implement a single tool to automate our analysis. Instead, we employ and implement a set of tools to reduce the analysis effort. Inevitably, we have to introduce manual analysis in RQ1. Our study mechanism has the following steps:

\subsubsection{Step 1. Collecting commits} All the projects in our study use Git\footnote{\url{https://git-scm.com/}} as their version control system. We implement a tool to check out all their commits. A typical commit log contains a commit id, an author name, the commit date, and a message. Once we get a commit id, our tool uses the \CodeIn{git show} command to list details, and then uses the textual \CodeIn{diff} command to produce its change hunks.

\subsubsection{Step 2. Identifying commits for the follow-up analysis} From collected commits, the second step is to extract commits that are related to concurrent code. Here, we consider that a commit is related to concurrent programming, if the commit involves synchronization, thread, or concurrent API classes. In this paper, we call such commits as \emph{concurrency-related commits}. A commit has a commit log that is written in natural language. The commit log often explains which files are modified and why programmers make such modifications. Our tool builds queries to search for commits that are related to concurrent programming. The built queries contain concurrency-related keywords. We choose 96 keywords as concurrency-related keywords. For example, \CodeIn{synchronized}, \CodeIn{volatile}, and concurrent API class names. The full list can be found in our project homepage\footnote{\url{https://github.com/qwordy/Research}}. However, this selector selects 11,868 commits that are too many for manual analysis. We selected a subset from them for manual analysis by checking whether a commit log contains concurrency-related keywords. The first selector selects 11,868 commits from 98,325 commits. The second selector selects 561 commits from the 11,868 commits that are output of the first selector. The size of the final selected set is 561. The precision is 0.67 based on a manual inspection.

The textual matching method can lose some useful commits. We used a machine learning method to select concurrency-related commits from the 11,868 commits as supplements. Researchers have explored related problems. For example, Tian \emph{et al.}~\cite{tian2012identifying} proposed an approach that identifies bug fixing patches with classification techniques. Motivated by their approach, we train a classifier to predict whether a commit is related to concurrent code. When training the classifier, our tool analyzes change hunks that are produced by the \CodeIn{diff} command, and uses the results as our code features. As shown in Table~\ref{table:feature}, in total, our tool extracts 12 features from each commit. The first column shows the feature names, and the second column shows the explanations. The keywords are the same as the concurrency-related keywords used in the previous paragragh. Our tool employs the SVM \cite{journals/ml/CortesV95} algorithm to identify commits that are related to concurrent programming. In particular, our tool is implemented based on a popular SVM library, LIBSVM \cite{libsvm}. As SVM is a supervised classification algorithm, it needs both labeled positive and negative data for training. We randomly selected 48 commits as a training set. We built the features of them, labelled them. The 48 commits have 15 positive instances and 35 negative instances. Then we trained a model and used it to classify commits. It selected 135 positive commits. The precision is 0.74 based on a manual inspection. The accurate recall is unavailable because if we can get all the positive instances, there is no need to use machine learning to classify.

We selected 696 commits for manual analysis in total.


%\zhong{Do you have overlaps between the two sets of commits? How many commits do you analyze in total?}


\begin{table}
	\centering
	\caption{Features of Data}\vspace*{-2ex}
	\label{table:feature}
	\begin{tabular}{|c|l|}\hline
		Feature&\multicolumn{1}{|c|}{Explanation}\\\hline
		msgKey&Number of keywords in commit message\\
		file&Number of files in a commit\\
		hunk&Number of hunks in a commit\\
		lineAdd&Number of added lines in a commit\\
		lineRemove&Number of removed lines in a commit\\
		lineSub&lineAdd - lineRemove\\
		lineSum&lineAdd + lineRemove\\
		keyAdd&Number of added keywords in a commit\\
		keyRemove&Number of removed keywords in a commit\\
		keySub&keyAdd - keyRemove\\
		keySum&keyAdd + keyRemove\\
		contextKey&Number of keywords in context code\\\hline
	\end{tabular}\vspace*{-3ex}
\end{table}

\subsubsection{Step 3. Analyzing commits according to different research questions} We then conduct detailed analysis according to our research questions.

%\textbf{RQ1. Determining change patterns.} To explore this research question, we manually analyze 696 concurrency-related commits. For example, the below is a concurrency-related commit. The top five lines describe the metadata of the commit. The other lines describe the differences between two versions of code. Due to the heavy manual effort, we randomly sample some commits from each project.

%For example, below is a concurrency-related commit. The top five lines describe the metadata of the commit. The other lines describe the differences between two versions of code.


%commit 563e546236217dace58a8031d56d08a27e08160b
%Author: zentol <s.motsu@web.de>
%Date:   Mon Jan 26 11:07:53 2015 +0100
%[FLINK-1419] [runtime] Fix: distributed ...

\textbf{RQ1. Determining change patterns.} To explore this research question, we analyzed each selected commit for their change patterns. For each commit, we first read the metadata and the corresponding issue to understand why programmers make the commit. After that, we scan change hunks to understand the details. In a change hunk, the ``+'' symbol denotes added lines, and the ``-'' symbol denotes removed lines. In some cases, it is infeasible to determine the category of a commit based on only its change hunks. For example, as change hunks are limited, it can be infeasible to determine the type of a variable. In such cases, we check out the original and modified versions of all files to analyze.
\begin{lstlisting}
public FutureTask<Path> createTmpFile(...) {
-    synchronized (count) {
+    synchronized (lock) {
\end{lstlisting}
In this example, we cannot determine the type of the \CodeIn{count} and \CodeIn{lock} variables. After we check out all files, we understand that the types of them are \CodeIn{Map} and \CodeIn{Object}, respectively.

We classify concurrency-related commits into different categories, mainly according to our observed code changes such as the modifications on code elements, parallel libraries, and control flows.

\textbf{RQ2. Exploring the usefulness of our change patterns.} We prepare a set of keywords for each change pattern, and search Github\footnote{\url{https://github.com}} for code where the pattern can apply. For example, we use \CodeIn{synchronized}, \CodeIn{put} or \CodeIn{get} as keywords to search code pieces that manually handle synchronization of collections. We find numerous code pieces in the search results. We manually check the code and decide whether it is acceptable for the pattern. If it is, we fork the project; make our changes; and submit the pull request.



%\zhong{Please explain what measure do you use to determine the correlations}


%\begin{figure}
%	\centering
%	\includegraphics[width=2in]{workflow}
%	\caption{Workflow}
%\end{figure}

%Figure 1 shows the basic workflow of our study. We first collect all the commits from the 7 projects using our tool. Then we use textual analysis and machine learning to select concurrent-related commits using our tool. Finally we manually analyze the potential concurrent-related commits to understand them.

%The first two steps have been described in Section Tool Support. Now we have got potential concurrent-related commits.
