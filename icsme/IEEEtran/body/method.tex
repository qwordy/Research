\section{Methodology}
\label{sec:method}
This section presents our research questions (Section~\ref{sec:method:rq}), our data set (Section~\ref{sec:method:data}), and our support tool (Section~\ref{sec:method:tool}).
\subsection{Research questions}
\label{sec:method:rq}
To understand how concurrency code is maintained, in this study, we focus on the following research questions:

\textbf{RQ1.} What patterns are followed when programmers maintain concurrency code?

In each day, programmers can make numerous commits. Based on their analysis on commits, Kim and Notkin~\cite{conf/icse/KimN09} find that code changes can be repetitive, and Martinez \emph{et al.}~\cite{conf/icsm/MartinezDM13} further extract change patterns to denote such repetitive changes. However, the change patterns of concurrency programming is rarely studied. The recent study~\cite{conf/sigsoft/GuJSZL15} mainly focuses on changes only on critical sections. As a result, this research question is still largely open. To explore this research question, we carefully put our selected concurrent-related commits into 6 categories (see Section~\ref{sec:result:rq1} for details).

\textbf{RQ2.} How useful are our extracted change patterns, when programmers maintain concurrency code?

To assess the usefulness of our extracted change patterns, we search open source search code in open-source projects with our change patterns. In particular, we search code in Github with a group of keywords of a pattern. We find numerous code pieces in the search results. We manually check the code and decide whether it is acceptable for the pattern. If it is, we fork the project, make our changes, commit and submit the pull request. Our changes have been accepted by the owner of some project\footnote{\url{https://github.com/derekmu/Schmince-2}}. See more details in Section~\ref{sec:result:sample}.

\textbf{RQ3.} What are the change trends of using parallel APIs?

J2SE\footnote{\url{https://docs.oracle.com/javase/}} provides standard APIs for developing concurrency code. Alternatively, programmers can use third-party libraries, since they provide similar and extensive functions. In practice, programmers can choose different APIs to implement their concurrency code. Their different choices can lead to different change trends that can be examined through their revision histories. For example, a parallel API can be difficult to use, so programmers have to constantly modify corresponding code, during software maintenance. In Section~\ref{sec:result:trend}, we count commits that involve different parallel APIs over time. We find 3 types of change trends. They are ascending trends (24\%), descending trends (8\%) and hybrid trends (68\%).%\zhong{Please add details.}

\textbf{RQ4.} Are there any correlations between code changes and changes on concurrency code?

Gu \emph{et al.}~\cite{conf/sigsoft/GuJSZL15} compare the code changes and changes on concurrency code, and they find strong correlation between the two types of code changes. With a different data set, we explore whether their finding still holds on other projects. Our results show that Spearman's rank correlation coefficient is 0.093.

\subsection{Data set}
\label{sec:method:data}
In this study, we collected commits from seven Apache\footnote{\url{http://www.apache.org/}} projects. Table~\ref{table:dataset} shows the details of our data set. We selected these projects, since they are popular and active. These projects cover various types of projects such as distributed computing, web server, database, information retrieval, I/O and machine learning. In particular, Hadoop is one of the most popular distributed computing frameworks in Java. Tomcat is a popular server. Cassandra is a database system that manages massive data. Solr is an enterprise search platform. Netty is an asynchronous network application framework. Flink is a stream processing framework. Mahout is a machine learning library. Column ``LOC'' lists the lines of code. Column ``\#Files'' lists number of source files. Column ``\#Commits'' lists number of commits. Column ``\#Selected Commits'' lists our manually investigated commits. We checked out all the commits in December 2016. The next section explains how we selected concurrency commits.

\begin{table}
	\centering
	\caption{Projects Information (LOC and \#Files are both of Java files)}
    \label{table:dataset}
	\begin{tabular}{|c|r|r|r|r|}\hline
		Project&\multicolumn{1}{|c|}{LOC}&\#Files&\#Commits&\#Selected Commits\\\hline
		Hadoop&1,202,764&7,701&14,930&49\\
		Tomcat&301,173&2,192&17,731&159\\
		Cassandra&387,980&2,143&21,982&48\\
		Lucene-solr&918,398&6,310&26,152&74\\
		Netty&218,131&2,054&7,759&202\\
		Flink&414,264&4,068&9,771&28\\\hline
		%Guava&251,205&1,672&3,850\\\hline
		%Mahout&109,584&1,215&3,703&0\\\hline
		Total&3,442,710&24,468&98,352&?\\\hline
	\end{tabular}
%\zhong{Add a total row. Remove Mahout, since you did not analyze its commits.}
\end{table}

\subsection{Study mechanism}
\label{sec:method:tool}
As introduced in Section~\ref{sec:intro}, it is quite difficult to implement a single tool to automate our analysis. Instead, we employ and implement a set of tools to reduce the analysis effort. Inevitably, we have to introduce manual analysis in several steps. Our study mechanism has the following steps:

\subsubsection{Step 1. Collecting commits} All the projects in our study use Git\footnote{\url{https://git-scm.com/}} as their version control system. We implement a tool to check out all their commits. A typical commit log contains a commit id, an author name, the commit date, and a message. Based on the Once we get a commit id, our tool uses the \texttt{git show} command to list details, and then uses the textual \texttt{diff} command to produce its change hunks.

\subsubsection{Step 2. Identifying commits for the follow-up analysis} From collected commits, the second step is to extract commits that are related to concurrency code. Here, we consider that a commit is related to concurrency programming, if the commit involves synchronization, thread, or concurrent API classes. In this paper, we call such commits as concurrency commits. A commit has a commit log that is written in natural language. The commit log often explains which files are modified and why programmers make such modifications. Our tool builds queries to search for commits that are related concurrency programming. The built queries contain keywords that are related to concurrency programming (\emph{e.g.}, \texttt{synchronized}, \texttt{volatile}, and related API class names). The search returns 561 commits.

The search alone can lose some useful commits. Researchers have explored related problems. For example, Tian \emph{et al.}~\cite{conf/icse/TianLL12} propose an approach that identifies bug fixing patches with classification techniques. Motivated by their approach, we train a classifier to predict whether a commit is related to concurrency code. When training the classifier, our tool analyzes change hunks that are produced by the \texttt{diff} command, and uses the results as our code features. As shown in Table~\ref{table:feature}, in total, our tool extracts 12 features from each commit. The first column shows the feature names, and the second column shows the explanations.
Our tool employs the SVM \cite{journals/ml/CortesV95} algorithm to identify commits that are related to concurrency programming. In particular, our tool is implemented based on the popular SVM library, LIBSVM \cite{libsvm}. As SVM is a supervised classification algorithm, it needs both labeled positive and negative data for training. We manually label some data as a training data set first then train a model. The trained classifier selects 135 positive instances from all the commits.

\zhong{Do you have overlaps between the two sets of commits? How many commits do you analysis in total?}

Finally we have 561 potential concurrent-related commits selected by keyword matching of commit message and 135 commits by using machine learning.

\begin{table}
	\centering
	\caption{Features of Data}
\label{table:feature}
	\begin{tabular}{|c|l|}\hline
		Feature&\multicolumn{1}{|c|}{Explanation}\\\hline
		msgKey&Number of keywords in commit message\\
		file&Number of files in a commit\\
		hunk&Number of hunks in a commit\\
		lineAdd&Number of added lines in a commit\\
		lineRemove&Number of removed lines in a commit\\
		lineSub&lineAdd - lineRemove\\
		lineSum&lineAdd + lineRemove\\
		keyAdd&Number of added keywords in a commit\\
		keyRemove&Number of removed keywords in a commit\\
		keySub&keyAdd - keyRemove\\
		keySum&keyAdd + keyRemove\\
		contextKey&Number of keywords in context code\\\hline
	\end{tabular}
\end{table}

\subsubsection{Step 3. Analyzing commits according to different research questions} We then conduct detailed analysis according to our research questions.



\textbf{RQ1. Determining change patterns.} To explore this research question, we manually analyze concurrency commits. For example, the below is a concurrency commit. The top five lines describe the metadata of the commit. The other lines describe the differences between two versions of code.

\begin{lstlisting}
commit 563e546236217dace58a8031d56d08a27e08160b
Author: zentol <s.motsu@web.de>
Date:   Mon Jan 26 11:07:53 2015 +0100
[FLINK-1419] [runtime] Fix: distributed cache properly synchronized
This closes #339

public FutureTask<Path> createTmpFile(String name, DistributedCacheEntry entry, JobID jobID) {
-    synchronized (count) {
-      Pair<JobID, String> key = new ImmutablePair<JobID, String>(jobID, name);
-      if (count.containsKey(key)) {
-        count.put(key, count.get(key) + 1);
+    synchronized (lock) {
+      if (!jobCounts.containsKey(jobID)) {
+        jobCounts.put(jobID, new HashMap<String, Integer>());
+      }
+      Map<String, Integer> count = jobCounts.get(jobID);
+      if (count.containsKey(name)) {
+        count.put(name, count.get(name) + 1);
       } else {
-        count.put(key, 1);
+        count.put(name, 1);
       }
     }
\end{lstlisting}

For each commit, we first read the metadata and the corresponding issue to understand why programmers make the commit. After that, we scan change hunks to understand the details. In a change hunk, the ``+'' symbol denotes added lines, and the ``-'' symbol denotes removed lines. In some cases, it is infeasible to determine the category of a commit based on only its change hunks. For example, as change hunks are limited, it can be infeasible to determine the type of a variable. In such cases, we check out the original and modified versions of all files to analyze. In this example, we cannot determine the type of the \texttt{count} and \texttt{lock} variables. After we check out all the files, we understand that the types of them are \texttt{Map} and \texttt{Object}, respectively.


We classify concurrency commits into different categories, mainly according to our observed code changes. During the classification, we consider various issues such as the modifications on code elements, parallel libraries, and control flows.

\textbf{RQ2. Exploring the usefulness of our change patterns.} We search the keywords of pattern in repositories. \zhong{Please explain how to build queries according to your patterns. Please explain how to you generate your patches?}


\textbf{RQ3. Determining the trends of using parallel APIs.} We count the usages of parallel APIs in the interval of months. \zhong{What are those parallel APIs? How you select them?}  To explore this research question, we analyze the trend of parallel APIs during the software evolution. In particular, we count the occurrence of 53 API classes. \zhong{How did you select these classes?} For each parallel API class, we draw a figure to denote its trend of modifications over time. Based on the shapes of such figures, we put parallel API classes into different categories. \zhong{How did you determine that a parallel class is related to a commit?}

\textbf{RQ4. Determining the correlations between commits and concurrency commits} \zhong{Please explain what measure do you use to determine the correlations}



%\begin{figure}
%	\centering
%	\includegraphics[width=2in]{workflow}
%	\caption{Workflow}
%\end{figure}

%Figure 1 shows the basic workflow of our study. We first collect all the commits from the 7 projects using our tool. Then we use textual analysis and machine learning to select concurrent-related commits using our tool. Finally we manually analyze the potential concurrent-related commits to understand them.

%The first two steps have been described in Section Tool Support. Now we have got potential concurrent-related commits.
